{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4621,
     "status": "ok",
     "timestamp": 1680192806171,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "010JsmvGnVEI",
    "outputId": "5f709ce0-6b3e-43b3-ebc6-1341b4a75e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
      "Requirement already satisfied: nlpaug in /usr/local/lib/python3.9/dist-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from nlpaug) (4.6.6)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from nlpaug) (1.4.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install the transformers library\n",
    "!pip install transformers nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1680192806171,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "ygC0wV6Zm2rn"
   },
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from pylab import plt, mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2571,
     "status": "ok",
     "timestamp": 1680192808731,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "z8Ew1KjMm3Zk",
    "outputId": "517ef07c-e381-4c7a-f70a-a47df3fc0fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "df_temp_onestock_example=pd.read_csv('/content/drive/MyDrive/HKU/COMP7409 Machine learning in trading and finance/Project/AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1680192808731,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "aaZp0WF3CH-1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1680192808731,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "xk28xwtCnlKM"
   },
   "outputs": [],
   "source": [
    "df_ori = df_temp_onestock_example\n",
    "temp =df_ori[['Date','concatcontent']].drop_duplicates()\n",
    "temp =df_ori\n",
    "text = df_ori.groupby(\"Date\")['concatcontent'].sum().to_frame(\"text\").reset_index()\n",
    "result = pd.merge(text,df_ori[['sscode','Date','adj_close_bef_tweet','adj_close_after_tweet','pct_ch_adj']].drop_duplicates(),on=['Date'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1680192809145,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "_UxhqAPMQDmY",
    "outputId": "3169a570-4398-40ab-9adc-20a748893301"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGhCAYAAABLWk8IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnaklEQVR4nO3dfXBU9aH/8U8e2IVAdtMA2U2uAQWrECGgoGHrE5WUABF1jFOtXIh3uHCli1PIvYipCIrWcKmjVG+APgqdIaWlI/YSngyhhGsJiJEMKQ+55cGbOLCJSskCXhKSnN8fv+Hcrobihjx8N7xfM2eGPee7Z7/niO7bs09RlmVZAgAAMEh0d08AAADgywgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYJxrCpRly5YpKipK8+bNs9ddvHhRfr9f/fv3V79+/ZSTk6O6urqQ+9XU1Cg7O1txcXFKSkrSggUL1NzcfC1TAQAAPUi7A2X//v366U9/qvT09JD18+fP16ZNm7RhwwaVlZXp1KlTevTRR+3tLS0tys7OVlNTk/bs2aO1a9dqzZo1Wrx4cfuPAgAA9ChR7fmxwPPnz+uOO+7QypUr9corr2j06NFasWKFGhoaNHDgQBUVFemxxx6TJB09elTDhw9XeXm5xo0bp61bt+rBBx/UqVOn5PF4JEmrV6/WwoUL9emnn8rhcFz18VtbW3Xq1CnFx8crKioq3OkDAIBuYFmWzp07p5SUFEVHX+UaidUOM2bMsObNm2dZlmXdf//91g9+8APLsiyrtLTUkmT99a9/DRk/aNAg6/XXX7csy7JeeOEFa9SoUSHbT5w4YUmyPvroozYf7+LFi1ZDQ4O9HD582JLEwsLCwsLCEoFLbW3tVVsjVmFav369PvroI+3fv/8r2wKBgBwOhxISEkLWezweBQIBe8zlKyd/u/3ytrYUFBTopZde+sr62tpauVyucA8BAAB0g2AwqNTUVMXHx191bFiBUltbqx/84AcqKSlR79692z3BcOXn5ysvL8++ffkAXS4XgQIAQIT5Om/PCOtNshUVFaqvr9cdd9yh2NhYxcbGqqysTG+++aZiY2Pl8XjU1NSks2fPhtyvrq5OXq9XkuT1er/yqZ7Lty+P+TKn02nHCFECAEDPF1agTJgwQVVVVaqsrLSXsWPHatq0afafe/XqpdLSUvs+1dXVqqmpkc/nkyT5fD5VVVWpvr7eHlNSUiKXy6W0tLQOOiwAABDJwnqJJz4+XiNGjAhZ17dvX/Xv399eP3PmTOXl5SkxMVEul0vPPPOMfD6fxo0bJ0maOHGi0tLSNH36dC1fvlyBQECLFi2S3++X0+nsoMMCAACRLOw3yV7NG2+8oejoaOXk5KixsVFZWVlauXKlvT0mJkbFxcWaM2eOfD6f+vbtq9zcXC1durSjpwIAACJUu74HpbsFg0G53W41NDTwfhQAACJEOM/f/BYPAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAME6Hf9U9AAD4Pzc+t7m7p9AuHy/L7tbH5woKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwTliBsmrVKqWnp8vlcsnlcsnn82nr1q329vHjxysqKipkefrpp0P2UVNTo+zsbMXFxSkpKUkLFixQc3NzxxwNAADoEWLDGXzDDTdo2bJl+uY3vynLsrR27Vo9/PDDOnDggG677TZJ0qxZs7R06VL7PnFxcfafW1palJ2dLa/Xqz179uj06dOaMWOGevXqpVdffbWDDgkAAES6sAJl6tSpIbd/9KMfadWqVdq7d68dKHFxcfJ6vW3e/7333tPhw4e1Y8cOeTwejR49Wi+//LIWLlyoF198UQ6Ho52HAQAAepJ2vwelpaVF69ev14ULF+Tz+ez169at04ABAzRixAjl5+friy++sLeVl5dr5MiR8ng89rqsrCwFg0EdOnToio/V2NioYDAYsgAAgJ4rrCsoklRVVSWfz6eLFy+qX79+2rhxo9LS0iRJTz75pAYPHqyUlBQdPHhQCxcuVHV1td555x1JUiAQCIkTSfbtQCBwxccsKCjQSy+9FO5UAQBAhAo7UG699VZVVlaqoaFBv//975Wbm6uysjKlpaVp9uzZ9riRI0cqOTlZEyZM0PHjxzV06NB2TzI/P195eXn27WAwqNTU1HbvDwAAmC3sl3gcDoduvvlmjRkzRgUFBRo1apR+8pOftDk2IyNDknTs2DFJktfrVV1dXciYy7ev9L4VSXI6nfYnhy4vAACg57rm70FpbW1VY2Njm9sqKyslScnJyZIkn8+nqqoq1dfX22NKSkrkcrnsl4kAAADCeoknPz9fkydP1qBBg3Tu3DkVFRVp165d2r59u44fP66ioiJNmTJF/fv318GDBzV//nzdd999Sk9PlyRNnDhRaWlpmj59upYvX65AIKBFixbJ7/fL6XR2ygECAIDIE1ag1NfXa8aMGTp9+rTcbrfS09O1fft2fec731Ftba127NihFStW6MKFC0pNTVVOTo4WLVpk3z8mJkbFxcWaM2eOfD6f+vbtq9zc3JDvTQEAAIiyLMvq7kmEKxgMyu12q6GhgfejAACMduNzm7t7Cu3y8bLsDt9nOM/f/BYPAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACME9vdEzDRjc9t7u4phO3jZdndPQUAADoMV1AAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxgkrUFatWqX09HS5XC65XC75fD5t3brV3n7x4kX5/X71799f/fr1U05Ojurq6kL2UVNTo+zsbMXFxSkpKUkLFixQc3NzxxwNAADoEcIKlBtuuEHLli1TRUWFPvzwQz3wwAN6+OGHdejQIUnS/PnztWnTJm3YsEFlZWU6deqUHn30Ufv+LS0tys7OVlNTk/bs2aO1a9dqzZo1Wrx4ccceFQAAiGhRlmVZ17KDxMRE/fjHP9Zjjz2mgQMHqqioSI899pgk6ejRoxo+fLjKy8s1btw4bd26VQ8++KBOnTolj8cjSVq9erUWLlyoTz/9VA6H42s9ZjAYlNvtVkNDg1wu17VMv0181T0AoKNE4nOK1DnPK+E8f7f7PSgtLS1av369Lly4IJ/Pp4qKCl26dEmZmZn2mGHDhmnQoEEqLy+XJJWXl2vkyJF2nEhSVlaWgsGgfRWmLY2NjQoGgyELAADoucIOlKqqKvXr109Op1NPP/20Nm7cqLS0NAUCATkcDiUkJISM93g8CgQCkqRAIBASJ5e3X952JQUFBXK73faSmpoa7rQBAEAECTtQbr31VlVWVmrfvn2aM2eOcnNzdfjw4c6Ymy0/P18NDQ32Ultb26mPBwAAuldsuHdwOBy6+eabJUljxozR/v379ZOf/ESPP/64mpqadPbs2ZCrKHV1dfJ6vZIkr9erDz74IGR/lz/lc3lMW5xOp5xOZ7hTBQAAEeqavweltbVVjY2NGjNmjHr16qXS0lJ7W3V1tWpqauTz+SRJPp9PVVVVqq+vt8eUlJTI5XIpLS3tWqcCAAB6iLCuoOTn52vy5MkaNGiQzp07p6KiIu3atUvbt2+X2+3WzJkzlZeXp8TERLlcLj3zzDPy+XwaN26cJGnixIlKS0vT9OnTtXz5cgUCAS1atEh+v58rJAAAwBZWoNTX12vGjBk6ffq03G630tPTtX37dn3nO9+RJL3xxhuKjo5WTk6OGhsblZWVpZUrV9r3j4mJUXFxsebMmSOfz6e+ffsqNzdXS5cu7dijAgAAEe2avwelO/A9KF/F96AAgJki8TlFiuDvQQEAAOgsBAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACME1agFBQU6M4771R8fLySkpL0yCOPqLq6OmTM+PHjFRUVFbI8/fTTIWNqamqUnZ2tuLg4JSUlacGCBWpubr72owEAAD1CbDiDy8rK5Pf7deedd6q5uVk//OEPNXHiRB0+fFh9+/a1x82aNUtLly61b8fFxdl/bmlpUXZ2trxer/bs2aPTp09rxowZ6tWrl1599dUOOCQAABDpwgqUbdu2hdxes2aNkpKSVFFRofvuu89eHxcXJ6/X2+Y+3nvvPR0+fFg7duyQx+PR6NGj9fLLL2vhwoV68cUX5XA42nEYAACgJ7mm96A0NDRIkhITE0PWr1u3TgMGDNCIESOUn5+vL774wt5WXl6ukSNHyuPx2OuysrIUDAZ16NChNh+nsbFRwWAwZAEAAD1XWFdQ/lZra6vmzZunu+++WyNGjLDXP/nkkxo8eLBSUlJ08OBBLVy4UNXV1XrnnXckSYFAICROJNm3A4FAm49VUFCgl156qb1TBQAAEabdgeL3+/XnP/9Z77//fsj62bNn238eOXKkkpOTNWHCBB0/flxDhw5t12Pl5+crLy/Pvh0MBpWamtq+iQMAAOO16yWeuXPnqri4WH/84x91ww03/N2xGRkZkqRjx45Jkrxer+rq6kLGXL59pfetOJ1OuVyukAUAAPRcYQWKZVmaO3euNm7cqJ07d+qmm2666n0qKyslScnJyZIkn8+nqqoq1dfX22NKSkrkcrmUlpYWznQAAEAPFdZLPH6/X0VFRfrDH/6g+Ph4+z0jbrdbffr00fHjx1VUVKQpU6aof//+OnjwoObPn6/77rtP6enpkqSJEycqLS1N06dP1/LlyxUIBLRo0SL5/X45nc6OP0IAABBxwrqCsmrVKjU0NGj8+PFKTk62l9/+9reSJIfDoR07dmjixIkaNmyY/vVf/1U5OTnatGmTvY+YmBgVFxcrJiZGPp9P//iP/6gZM2aEfG8KAAC4voV1BcWyrL+7PTU1VWVlZVfdz+DBg7Vly5ZwHhoAAFxH+C0eAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxgkrUAoKCnTnnXcqPj5eSUlJeuSRR1RdXR0y5uLFi/L7/erfv7/69eunnJwc1dXVhYypqalRdna24uLilJSUpAULFqi5ufnajwYAAPQIYQVKWVmZ/H6/9u7dq5KSEl26dEkTJ07UhQsX7DHz58/Xpk2btGHDBpWVlenUqVN69NFH7e0tLS3Kzs5WU1OT9uzZo7Vr12rNmjVavHhxxx0VAACIaFGWZVntvfOnn36qpKQklZWV6b777lNDQ4MGDhyooqIiPfbYY5Kko0ePavjw4SovL9e4ceO0detWPfjggzp16pQ8Ho8kafXq1Vq4cKE+/fRTORyOqz5uMBiU2+1WQ0ODXC5Xe6d/RTc+t7nD99nZPl6W3d1TAAC0IRKfU6TOeV4J5/n7mt6D0tDQIElKTEyUJFVUVOjSpUvKzMy0xwwbNkyDBg1SeXm5JKm8vFwjR46040SSsrKyFAwGdejQoTYfp7GxUcFgMGQBAAA9V7sDpbW1VfPmzdPdd9+tESNGSJICgYAcDocSEhJCxno8HgUCAXvM38bJ5e2Xt7WloKBAbrfbXlJTU9s7bQAAEAHaHSh+v19//vOftX79+o6cT5vy8/PV0NBgL7W1tZ3+mAAAoPvEtudOc+fOVXFxsXbv3q0bbrjBXu/1etXU1KSzZ8+GXEWpq6uT1+u1x3zwwQch+7v8KZ/LY77M6XTK6XS2Z6oAACAChXUFxbIszZ07Vxs3btTOnTt10003hWwfM2aMevXqpdLSUntddXW1ampq5PP5JEk+n09VVVWqr6+3x5SUlMjlciktLe1ajgUAAPQQYV1B8fv9Kioq0h/+8AfFx8fb7xlxu93q06eP3G63Zs6cqby8PCUmJsrlcumZZ56Rz+fTuHHjJEkTJ05UWlqapk+fruXLlysQCGjRokXy+/1cJQEAAJLCDJRVq1ZJksaPHx+y/u2339ZTTz0lSXrjjTcUHR2tnJwcNTY2KisrSytXrrTHxsTEqLi4WHPmzJHP51Pfvn2Vm5urpUuXXtuRAACAHiOsQPk6X5nSu3dvFRYWqrCw8IpjBg8erC1btoTz0AAA4DrCb/EAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwTtiBsnv3bk2dOlUpKSmKiorSu+++G7L9qaeeUlRUVMgyadKkkDFnzpzRtGnT5HK5lJCQoJkzZ+r8+fPXdCAAAKDnCDtQLly4oFGjRqmwsPCKYyZNmqTTp0/by29+85uQ7dOmTdOhQ4dUUlKi4uJi7d69W7Nnzw5/9gAAoEeKDfcOkydP1uTJk//uGKfTKa/X2+a2I0eOaNu2bdq/f7/Gjh0rSXrrrbc0ZcoUvfbaa0pJSQl3SgAAoIfplPeg7Nq1S0lJSbr11ls1Z84cff755/a28vJyJSQk2HEiSZmZmYqOjta+ffva3F9jY6OCwWDIAgAAeq4OD5RJkybp17/+tUpLS/Xv//7vKisr0+TJk9XS0iJJCgQCSkpKCrlPbGysEhMTFQgE2txnQUGB3G63vaSmpnb0tAEAgEHCfonnap544gn7zyNHjlR6erqGDh2qXbt2acKECe3aZ35+vvLy8uzbwWCQSAEAoAfr9I8ZDxkyRAMGDNCxY8ckSV6vV/X19SFjmpubdebMmSu+b8XpdMrlcoUsAACg5+r0QPnkk0/0+eefKzk5WZLk8/l09uxZVVRU2GN27typ1tZWZWRkdPZ0AABABAj7JZ7z58/bV0Mk6eTJk6qsrFRiYqISExP10ksvKScnR16vV8ePH9ezzz6rm2++WVlZWZKk4cOHa9KkSZo1a5ZWr16tS5cuae7cuXriiSf4BA8AAJDUjisoH374oW6//XbdfvvtkqS8vDzdfvvtWrx4sWJiYnTw4EE99NBDuuWWWzRz5kyNGTNG//Vf/yWn02nvY926dRo2bJgmTJigKVOm6J577tHPfvazjjsqAAAQ0cK+gjJ+/HhZlnXF7du3b7/qPhITE1VUVBTuQwMAgOsEv8UDAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOGEHyu7duzV16lSlpKQoKipK7777bsh2y7K0ePFiJScnq0+fPsrMzNRf/vKXkDFnzpzRtGnT5HK5lJCQoJkzZ+r8+fPXdCAAAKDnCDtQLly4oFGjRqmwsLDN7cuXL9ebb76p1atXa9++ferbt6+ysrJ08eJFe8y0adN06NAhlZSUqLi4WLt379bs2bPbfxQAAKBHiQ33DpMnT9bkyZPb3GZZllasWKFFixbp4YcfliT9+te/lsfj0bvvvqsnnnhCR44c0bZt27R//36NHTtWkvTWW29pypQpeu2115SSknINhwMAAHqCDn0PysmTJxUIBJSZmWmvc7vdysjIUHl5uSSpvLxcCQkJdpxIUmZmpqKjo7Vv374299vY2KhgMBiyAACAnqtDAyUQCEiSPB5PyHqPx2NvCwQCSkpKCtkeGxurxMREe8yXFRQUyO1220tqampHThsAABgmIj7Fk5+fr4aGBnupra3t7ikBAIBO1KGB4vV6JUl1dXUh6+vq6uxtXq9X9fX1Idubm5t15swZe8yXOZ1OuVyukAUAAPRcHRooN910k7xer0pLS+11wWBQ+/btk8/nkyT5fD6dPXtWFRUV9pidO3eqtbVVGRkZHTkdAAAQocL+FM/58+d17Ngx+/bJkydVWVmpxMREDRo0SPPmzdMrr7yib37zm7rpppv0wgsvKCUlRY888ogkafjw4Zo0aZJmzZql1atX69KlS5o7d66eeOIJPsEDAAAktSNQPvzwQ33729+2b+fl5UmScnNztWbNGj377LO6cOGCZs+erbNnz+qee+7Rtm3b1Lt3b/s+69at09y5czVhwgRFR0crJydHb775ZgccDgAA6AmiLMuyunsS4QoGg3K73WpoaOiU96Pc+NzmDt9nZ/t4WXZ3TwEA0IZIfE6ROud5JZzn74j4FA8AALi+ECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACM0+GB8uKLLyoqKipkGTZsmL394sWL8vv96t+/v/r166ecnBzV1dV19DQAAEAE65QrKLfddptOnz5tL++//769bf78+dq0aZM2bNigsrIynTp1So8++mhnTAMAAESo2E7ZaWysvF7vV9Y3NDTol7/8pYqKivTAAw9Ikt5++20NHz5ce/fu1bhx49rcX2NjoxobG+3bwWCwM6YNAAAM0SlXUP7yl78oJSVFQ4YM0bRp01RTUyNJqqio0KVLl5SZmWmPHTZsmAYNGqTy8vIr7q+goEBut9teUlNTO2PaAADAEB0eKBkZGVqzZo22bdumVatW6eTJk7r33nt17tw5BQIBORwOJSQkhNzH4/EoEAhccZ/5+flqaGiwl9ra2o6eNgAAMEiHv8QzefJk+8/p6enKyMjQ4MGD9bvf/U59+vRp1z6dTqecTmdHTREAABiu0z9mnJCQoFtuuUXHjh2T1+tVU1OTzp49GzKmrq6uzfesAACA61OnB8r58+d1/PhxJScna8yYMerVq5dKS0vt7dXV1aqpqZHP5+vsqQAAgAjR4S/x/Nu//ZumTp2qwYMH69SpU1qyZIliYmL0ve99T263WzNnzlReXp4SExPlcrn0zDPPyOfzXfETPAAA4PrT4YHyySef6Hvf+54+//xzDRw4UPfcc4/27t2rgQMHSpLeeOMNRUdHKycnR42NjcrKytLKlSs7ehoAACCCdXigrF+//u9u7927twoLC1VYWNjRDw0AAHoIfosHAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcbo1UAoLC3XjjTeqd+/eysjI0AcffNCd0wEAAIbotkD57W9/q7y8PC1ZskQfffSRRo0apaysLNXX13fXlAAAgCFiu+uBX3/9dc2aNUv/9E//JElavXq1Nm/erF/96ld67rnnQsY2NjaqsbHRvt3Q0CBJCgaDnTK31sYvOmW/namzzgUA4NpE4nOK1DnPK5f3aVnW1Qdb3aCxsdGKiYmxNm7cGLJ+xowZ1kMPPfSV8UuWLLEksbCwsLCwsPSApba29qqt0C1XUD777DO1tLTI4/GErPd4PDp69OhXxufn5ysvL8++3draqjNnzqh///6Kiorq0LkFg0GlpqaqtrZWLperQ/eN/8N57hqc567Bee4anOeu01nn2rIsnTt3TikpKVcd220v8YTD6XTK6XSGrEtISOjUx3S5XPwL0AU4z12D89w1OM9dg/PcdTrjXLvd7q81rlveJDtgwADFxMSorq4uZH1dXZ28Xm93TAkAABikWwLF4XBozJgxKi0ttde1traqtLRUPp+vO6YEAAAM0m0v8eTl5Sk3N1djx47VXXfdpRUrVujChQv2p3q6i9Pp1JIlS77ykhI6Fue5a3CeuwbnuWtwnruOCec6yrK+zmd9Osd//Md/6Mc//rECgYBGjx6tN998UxkZGd01HQAAYIhuDRQAAIC28Fs8AADAOAQKAAAwDoECAACMQ6AAAADjXJeBUlhYqBtvvFG9e/dWRkaGPvjgg787fsOGDRo2bJh69+6tkSNHasuWLV0008gWznn++c9/rnvvvVff+MY39I1vfEOZmZlX/eeC/y/cv8+XrV+/XlFRUXrkkUc6d4I9RLjn+ezZs/L7/UpOTpbT6dQtt9zCfzu+hnDP84oVK3TrrbeqT58+Sk1N1fz583Xx4sUumm1k2r17t6ZOnaqUlBRFRUXp3Xffvep9du3apTvuuENOp1M333yz1qxZ0+nz7JYfC+xO69evtxwOh/WrX/3KOnTokDVr1iwrISHBqqura3P8n/70JysmJsZavny5dfjwYWvRokVWr169rKqqqi6eeWQJ9zw/+eSTVmFhoXXgwAHryJEj1lNPPWW53W7rk08+6eKZR5Zwz/NlJ0+etP7hH/7Buvfee62HH364ayYbwcI9z42NjdbYsWOtKVOmWO+//7518uRJa9euXVZlZWUXzzyyhHue161bZzmdTmvdunXWyZMnre3bt1vJycnW/Pnzu3jmkWXLli3W888/b73zzjuWpK/8cO+XnThxwoqLi7Py8vKsw4cPW2+99ZYVExNjbdu2rVPned0Fyl133WX5/X77dktLi5WSkmIVFBS0Of673/2ulZ2dHbIuIyPD+pd/+ZdOnWekC/c8f1lzc7MVHx9vrV27trOm2CO05zw3Nzdb3/rWt6xf/OIXVm5uLoHyNYR7nletWmUNGTLEampq6qop9gjhnme/32898MADIevy8vKsu+++u1Pn2ZN8nUB59tlnrdtuuy1k3eOPP25lZWV14sws67p6iaepqUkVFRXKzMy010VHRyszM1Pl5eVt3qe8vDxkvCRlZWVdcTzad56/7IsvvtClS5eUmJjYWdOMeO09z0uXLlVSUpJmzpzZFdOMeO05z//5n/8pn88nv98vj8ejESNG6NVXX1VLS0tXTTvitOc8f+tb31JFRYX9MtCJEye0ZcsWTZkypUvmfL3orufBiPg1447y2WefqaWlRR6PJ2S9x+PR0aNH27xPIBBoc3wgEOi0eUa69pznL1u4cKFSUlK+8i8F/k97zvP777+vX/7yl6qsrOyCGfYM7TnPJ06c0M6dOzVt2jRt2bJFx44d0/e//31dunRJS5Ys6YppR5z2nOcnn3xSn332me655x5ZlqXm5mY9/fTT+uEPf9gVU75uXOl5MBgM6n//93/Vp0+fTnnc6+oKCiLDsmXLtH79em3cuFG9e/fu7un0GOfOndP06dP185//XAMGDOju6fRora2tSkpK0s9+9jONGTNGjz/+uJ5//nmtXr26u6fWo+zatUuvvvqqVq5cqY8++kjvvPOONm/erJdffrm7p4YOcF1dQRkwYIBiYmJUV1cXsr6urk5er7fN+3i93rDGo33n+bLXXntNy5Yt044dO5Sent6Z04x44Z7n48eP6+OPP9bUqVPtda2trZKk2NhYVVdXa+jQoZ076QjUnr/PycnJ6tWrl2JiYux1w4cPVyAQUFNTkxwOR6fOORK15zy/8MILmj59uv75n/9ZkjRy5EhduHBBs2fP1vPPP6/oaP4fvCNc6XnQ5XJ12tUT6Tq7guJwODRmzBiVlpba61pbW1VaWiqfz9fmfXw+X8h4SSopKbnieLTvPEvS8uXL9fLLL2vbtm0aO3ZsV0w1ooV7nocNG6aqqipVVlbay0MPPaRvf/vbqqysVGpqaldOP2K05+/z3XffrWPHjtkBKEn//d//reTkZOLkCtpznr/44ouvRMjlKLT4mbkO023Pg536FlwDrV+/3nI6ndaaNWusw4cPW7Nnz7YSEhKsQCBgWZZlTZ8+3Xruuefs8X/605+s2NhY67XXXrOOHDliLVmyhI8Zfw3hnudly5ZZDofD+v3vf2+dPn3aXs6dO9ddhxARwj3PX8aneL6ecM9zTU2NFR8fb82dO9eqrq62iouLraSkJOuVV17prkOICOGe5yVLlljx8fHWb37zG+vEiRPWe++9Zw0dOtT67ne/212HEBHOnTtnHThwwDpw4IAlyXr99detAwcOWP/zP/9jWZZlPffcc9b06dPt8Zc/ZrxgwQLryJEjVmFhIR8z7ixvvfWWNWjQIMvhcFh33XWXtXfvXnvb/fffb+Xm5oaM/93vfmfdcsstlsPhsG677TZr8+bNXTzjyBTOeR48eLAl6SvLkiVLun7iESbcv89/i0D5+sI9z3v27LEyMjIsp9NpDRkyxPrRj35kNTc3d/GsI0845/nSpUvWiy++aA0dOtTq3bu3lZqaan3/+9+3/vrXv3b9xCPIH//4xzb/e3v53Obm5lr333//V+4zevRoy+FwWEOGDLHefvvtTp9nlGVxHQwAAJjlunoPCgAAiAwECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIzz/wBGnAxWRMy39wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (result['pct_ch_adj'] <= 0),\n",
    "    (result['pct_ch_adj'] > 0)\n",
    "    ]\n",
    "values = [0, 1]\n",
    "result['label'] = np.select(conditions, values)\n",
    "plt.hist(result['label'])\n",
    "df=result[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1680192809146,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "HMDNDf2CMACy"
   },
   "outputs": [],
   "source": [
    "train_df, valid_test_df = train_test_split(df, test_size=0.4,random_state=42)\n",
    "valid_df, test_df = train_test_split(valid_test_df, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1680194968397,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "RqOT5VztC5cV"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('/content/drive/MyDrive/HKU/COMP7409 Machine learning in trading and finance/Project/train_df.csv', index=False)\n",
    "valid_df.to_csv('/content/drive/MyDrive/HKU/COMP7409 Machine learning in trading and finance/Project/valid_df.csv', index=False)\n",
    "test_df.to_csv('/content/drive/MyDrive/HKU/COMP7409 Machine learning in trading and finance/Project/test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1680192809831,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "6f2lrQkln7cH"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13995,
     "status": "ok",
     "timestamp": 1680192823810,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "91-53Z-wNZTG",
    "outputId": "4e47294f-d7e0-41bd-a9a4-657eb16de644"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def encode_data(tokenizer, texts, labels, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        token_data = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "        input_ids.append(token_data[\"input_ids\"])\n",
    "        attention_masks.append(token_data[\"attention_mask\"])\n",
    "\n",
    "    input_ids = tf.concat(input_ids, axis=0)\n",
    "    attention_masks = tf.concat(attention_masks, axis=0)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "max_length = 128\n",
    "train_input_ids, train_attention_masks, train_labels = encode_data(tokenizer, train_df[\"text\"].tolist(), train_df[\"label\"].tolist(), max_length)\n",
    "test_input_ids, test_attention_masks, test_labels = encode_data(tokenizer, test_df[\"text\"].tolist(), test_df[\"label\"].tolist(), max_length)\n",
    "valid_input_ids, valid_attention_masks, valid_labels = encode_data(tokenizer, valid_df[\"text\"].tolist(), valid_df[\"label\"].tolist(), max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1680192823810,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "iadxGr2wZNR-"
   },
   "outputs": [],
   "source": [
    "# Step 3: Apply data augmentation to the training data\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57140,
     "status": "ok",
     "timestamp": 1680192880943,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "alG-o-WZZNPF",
    "outputId": "68246413-68ed-4d10-e9cf-b750c52b626a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-bbabad2898e1>:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df_augmented = train_df_augmented.append(pd.DataFrame({\"text\": augmented_texts, \"label\": augmented_labels}), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def augment_text(text, augmenters, num_augmented_texts_per_augmenter=1):\n",
    "    augmented_texts = []\n",
    "\n",
    "    for augmenter in augmenters:\n",
    "        for _ in range(num_augmented_texts_per_augmenter):\n",
    "            augmented_texts.append(augmenter.augment(text))\n",
    "\n",
    "    return augmented_texts\n",
    "\n",
    "\n",
    "# Initialize multiple augmenters\n",
    "synonym_augmenter = naw.SynonymAug()\n",
    "deletion_augmenter = naw.RandomWordAug(action=\"delete\")\n",
    "order_augmenter = naw.RandomWordAug(action=\"swap\")\n",
    "\n",
    "augmenters = [synonym_augmenter, deletion_augmenter, order_augmenter]\n",
    "\n",
    "# Apply data augmentation to the training data\n",
    "num_augmented_texts_per_augmenter = 1\n",
    "augmented_texts = []\n",
    "augmented_labels = []\n",
    "\n",
    "for text, label in zip(train_df[\"text\"], train_df[\"label\"]):\n",
    "    augmented = augment_text(text, augmenters, num_augmented_texts_per_augmenter)\n",
    "    augmented_texts.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "# Combine the original and augmented data\n",
    "train_df_augmented = train_df.copy()\n",
    "train_df_augmented = train_df_augmented.append(pd.DataFrame({\"text\": augmented_texts, \"label\": augmented_labels}), ignore_index=True)\n",
    "\n",
    "# Tokenize and encode the augmented data\n",
    "train_input_ids, train_attention_masks, train_labels = encode_data(tokenizer, train_df_augmented[\"text\"].tolist(), train_df_augmented[\"label\"].tolist(), max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1680192880945,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "Hnv9Mf9-NZQR"
   },
   "outputs": [],
   "source": [
    "# Step 4: Build the custom model\n",
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746,
     "referenced_widgets": [
      "c6d85307452b4eaba9cda91954ca3093",
      "1266ba7ee9e347ada3c42b945ea562ab",
      "f46cb9695cc7431781c675fa6a052dfa",
      "72ea02f182c04e2b87e32cfb813ba1d5",
      "1f56f90ecfa147f299a1fd95b602a776",
      "2eb656f8ce664c76afec024b5dc43b87",
      "4e80cf3471f14159a5c1c709f4c5e2e8",
      "67445718b5dc492bbeb0a24cb3fb83e3",
      "e2bb40050f20431eae41e104387fa6fe",
      "2f35d66abecc4521a7b653c1990145b7",
      "7b6c869f8baa4c94a1157ba1f0453c9c"
     ]
    },
    "executionInfo": {
     "elapsed": 13826,
     "status": "ok",
     "timestamp": 1680192894757,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "pylLzDFsNZNt",
    "outputId": "2d27f608-6a8b-4f92-db4b-ee39505f3476"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d85307452b4eaba9cda91954ca3093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128)          426496      ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 128)          0           ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            130         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,917,122\n",
      "Trainable params: 434,882\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.trainable = False\n",
    "# bert_model.trainable = True\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_masks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_masks\")\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_masks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_masks\")\n",
    "\n",
    "bert_output = bert_model([input_ids, attention_masks])[0]\n",
    "lstm_output = Bidirectional(LSTM(64, return_sequences=False))(bert_output)\n",
    "dropout = Dropout(0.5)(lstm_output)\n",
    "dense1 = Dense(64, activation=\"relu\")(dropout)\n",
    "dropout2 = Dropout(0.5)(dense1)\n",
    "output = Dense(2, activation=\"softmax\")(dropout2)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1902246,
     "status": "ok",
     "timestamp": 1680194831618,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "yQB6IKCpNZFD",
    "outputId": "d3b2534f-c2ed-43b1-ae61-adcea902776e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 48s 411ms/step - loss: 0.7378 - accuracy: 0.5228 - val_loss: 0.7085 - val_accuracy: 0.4460\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 19s 369ms/step - loss: 0.7238 - accuracy: 0.4976 - val_loss: 0.7058 - val_accuracy: 0.4676\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.7178 - accuracy: 0.4976 - val_loss: 0.7036 - val_accuracy: 0.5036\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.7114 - accuracy: 0.5054 - val_loss: 0.7021 - val_accuracy: 0.5108\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 20s 374ms/step - loss: 0.7007 - accuracy: 0.5126 - val_loss: 0.7002 - val_accuracy: 0.4964\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 19s 354ms/step - loss: 0.6995 - accuracy: 0.5252 - val_loss: 0.7006 - val_accuracy: 0.5036\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 18s 344ms/step - loss: 0.7022 - accuracy: 0.5252 - val_loss: 0.6989 - val_accuracy: 0.5036\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.6970 - accuracy: 0.5252 - val_loss: 0.6971 - val_accuracy: 0.4892\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.6969 - accuracy: 0.5168 - val_loss: 0.6973 - val_accuracy: 0.4892\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6980 - accuracy: 0.5228 - val_loss: 0.6947 - val_accuracy: 0.4892\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6963 - accuracy: 0.5330 - val_loss: 0.6944 - val_accuracy: 0.4892\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.7040 - accuracy: 0.5246 - val_loss: 0.6936 - val_accuracy: 0.4748\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6912 - accuracy: 0.5318 - val_loss: 0.6936 - val_accuracy: 0.4676\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.7005 - accuracy: 0.5258 - val_loss: 0.6953 - val_accuracy: 0.4820\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6919 - accuracy: 0.5318 - val_loss: 0.6952 - val_accuracy: 0.4892\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6910 - accuracy: 0.5390 - val_loss: 0.6958 - val_accuracy: 0.4892\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6944 - accuracy: 0.5210 - val_loss: 0.6945 - val_accuracy: 0.4892\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6945 - accuracy: 0.5126 - val_loss: 0.6945 - val_accuracy: 0.4820\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6923 - accuracy: 0.5264 - val_loss: 0.6947 - val_accuracy: 0.4820\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6918 - accuracy: 0.5294 - val_loss: 0.6976 - val_accuracy: 0.4892\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6908 - accuracy: 0.5384 - val_loss: 0.6989 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6952 - accuracy: 0.5096 - val_loss: 0.6969 - val_accuracy: 0.4820\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6893 - accuracy: 0.5300 - val_loss: 0.6979 - val_accuracy: 0.4748\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.6876 - accuracy: 0.5510 - val_loss: 0.6977 - val_accuracy: 0.4676\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6872 - accuracy: 0.5504 - val_loss: 0.6987 - val_accuracy: 0.4892\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6906 - accuracy: 0.5324 - val_loss: 0.6996 - val_accuracy: 0.4964\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6868 - accuracy: 0.5432 - val_loss: 0.7004 - val_accuracy: 0.4820\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6860 - accuracy: 0.5498 - val_loss: 0.7024 - val_accuracy: 0.4820\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6868 - accuracy: 0.5360 - val_loss: 0.7040 - val_accuracy: 0.4532\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6859 - accuracy: 0.5300 - val_loss: 0.7038 - val_accuracy: 0.4748\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.6838 - accuracy: 0.5546 - val_loss: 0.7052 - val_accuracy: 0.4676\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 19s 360ms/step - loss: 0.6856 - accuracy: 0.5516 - val_loss: 0.7047 - val_accuracy: 0.4748\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6871 - accuracy: 0.5414 - val_loss: 0.7045 - val_accuracy: 0.4604\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6864 - accuracy: 0.5468 - val_loss: 0.7096 - val_accuracy: 0.4604\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 18s 337ms/step - loss: 0.6802 - accuracy: 0.5576 - val_loss: 0.7125 - val_accuracy: 0.4532\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.6844 - accuracy: 0.5354 - val_loss: 0.7140 - val_accuracy: 0.4604\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6847 - accuracy: 0.5438 - val_loss: 0.7184 - val_accuracy: 0.4676\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6859 - accuracy: 0.5432 - val_loss: 0.7174 - val_accuracy: 0.4820\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6766 - accuracy: 0.5695 - val_loss: 0.7174 - val_accuracy: 0.4820\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6780 - accuracy: 0.5629 - val_loss: 0.7230 - val_accuracy: 0.4820\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6757 - accuracy: 0.5528 - val_loss: 0.7231 - val_accuracy: 0.4676\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6775 - accuracy: 0.5552 - val_loss: 0.7285 - val_accuracy: 0.4820\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6785 - accuracy: 0.5504 - val_loss: 0.7327 - val_accuracy: 0.4604\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6772 - accuracy: 0.5618 - val_loss: 0.7325 - val_accuracy: 0.4892\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6747 - accuracy: 0.5600 - val_loss: 0.7365 - val_accuracy: 0.4748\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6813 - accuracy: 0.5390 - val_loss: 0.7319 - val_accuracy: 0.4964\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6752 - accuracy: 0.5522 - val_loss: 0.7368 - val_accuracy: 0.4892\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6764 - accuracy: 0.5629 - val_loss: 0.7360 - val_accuracy: 0.4748\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6742 - accuracy: 0.5624 - val_loss: 0.7397 - val_accuracy: 0.4820\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6703 - accuracy: 0.5653 - val_loss: 0.7430 - val_accuracy: 0.4892\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6697 - accuracy: 0.5635 - val_loss: 0.7533 - val_accuracy: 0.4604\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6661 - accuracy: 0.5552 - val_loss: 0.7695 - val_accuracy: 0.4604\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 18s 336ms/step - loss: 0.6664 - accuracy: 0.5725 - val_loss: 0.7578 - val_accuracy: 0.4892\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6665 - accuracy: 0.5606 - val_loss: 0.7707 - val_accuracy: 0.4532\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6738 - accuracy: 0.5624 - val_loss: 0.7745 - val_accuracy: 0.4317\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6620 - accuracy: 0.5791 - val_loss: 0.7733 - val_accuracy: 0.4676\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6620 - accuracy: 0.5761 - val_loss: 0.7807 - val_accuracy: 0.5252\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6561 - accuracy: 0.5695 - val_loss: 0.8016 - val_accuracy: 0.4460\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6550 - accuracy: 0.5707 - val_loss: 0.8023 - val_accuracy: 0.5108\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6591 - accuracy: 0.5815 - val_loss: 0.8070 - val_accuracy: 0.4604\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6530 - accuracy: 0.5809 - val_loss: 0.8080 - val_accuracy: 0.4676\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6528 - accuracy: 0.5827 - val_loss: 0.8083 - val_accuracy: 0.5108\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6508 - accuracy: 0.5815 - val_loss: 0.8286 - val_accuracy: 0.4820\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.6478 - accuracy: 0.5953 - val_loss: 0.8454 - val_accuracy: 0.4748\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6485 - accuracy: 0.5785 - val_loss: 0.8872 - val_accuracy: 0.4604\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6401 - accuracy: 0.5923 - val_loss: 0.8798 - val_accuracy: 0.5036\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6375 - accuracy: 0.5947 - val_loss: 0.9072 - val_accuracy: 0.4892\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 18s 335ms/step - loss: 0.6503 - accuracy: 0.5683 - val_loss: 0.8759 - val_accuracy: 0.4964\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6368 - accuracy: 0.5959 - val_loss: 0.9062 - val_accuracy: 0.5108\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 19s 357ms/step - loss: 0.6324 - accuracy: 0.5977 - val_loss: 0.9192 - val_accuracy: 0.5108\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6308 - accuracy: 0.5869 - val_loss: 0.9304 - val_accuracy: 0.5036\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.6264 - accuracy: 0.6097 - val_loss: 0.9433 - val_accuracy: 0.5036\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6282 - accuracy: 0.6037 - val_loss: 0.9537 - val_accuracy: 0.4820\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6252 - accuracy: 0.5989 - val_loss: 0.9651 - val_accuracy: 0.4892\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6246 - accuracy: 0.6103 - val_loss: 0.9873 - val_accuracy: 0.5180\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6215 - accuracy: 0.6025 - val_loss: 0.9875 - val_accuracy: 0.5396\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.6192 - accuracy: 0.5935 - val_loss: 0.9912 - val_accuracy: 0.5036\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.6076 - accuracy: 0.6169 - val_loss: 1.0516 - val_accuracy: 0.4964\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6194 - accuracy: 0.6019 - val_loss: 1.0491 - val_accuracy: 0.4964\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.6048 - accuracy: 0.6157 - val_loss: 1.0856 - val_accuracy: 0.4604\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.6186 - accuracy: 0.5833 - val_loss: 1.1152 - val_accuracy: 0.4748\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 18s 336ms/step - loss: 0.6043 - accuracy: 0.6283 - val_loss: 1.0943 - val_accuracy: 0.4892\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 19s 360ms/step - loss: 0.5994 - accuracy: 0.6187 - val_loss: 1.0791 - val_accuracy: 0.5252\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.5830 - accuracy: 0.6259 - val_loss: 1.1550 - val_accuracy: 0.5252\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.6017 - accuracy: 0.6217 - val_loss: 1.1520 - val_accuracy: 0.4676\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5945 - accuracy: 0.6175 - val_loss: 1.1955 - val_accuracy: 0.4964\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5893 - accuracy: 0.6259 - val_loss: 1.2092 - val_accuracy: 0.5468\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5878 - accuracy: 0.6229 - val_loss: 1.2238 - val_accuracy: 0.5108\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 18s 332ms/step - loss: 0.5952 - accuracy: 0.6223 - val_loss: 1.2351 - val_accuracy: 0.5324\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.5703 - accuracy: 0.6295 - val_loss: 1.2745 - val_accuracy: 0.5324\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.5768 - accuracy: 0.6397 - val_loss: 1.3224 - val_accuracy: 0.5252\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.5696 - accuracy: 0.6463 - val_loss: 1.3316 - val_accuracy: 0.5324\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5881 - accuracy: 0.6145 - val_loss: 1.3714 - val_accuracy: 0.5324\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 19s 359ms/step - loss: 0.5725 - accuracy: 0.6319 - val_loss: 1.3446 - val_accuracy: 0.5180\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 18s 333ms/step - loss: 0.5722 - accuracy: 0.6301 - val_loss: 1.3378 - val_accuracy: 0.5252\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 18s 336ms/step - loss: 0.5666 - accuracy: 0.6325 - val_loss: 1.3605 - val_accuracy: 0.5324\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5695 - accuracy: 0.6391 - val_loss: 1.3628 - val_accuracy: 0.5252\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 19s 360ms/step - loss: 0.5778 - accuracy: 0.6295 - val_loss: 1.4123 - val_accuracy: 0.5036\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 18s 334ms/step - loss: 0.5625 - accuracy: 0.6307 - val_loss: 1.4893 - val_accuracy: 0.4820\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 19s 358ms/step - loss: 0.5649 - accuracy: 0.6301 - val_loss: 1.5032 - val_accuracy: 0.4892\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train and evaluate the model using the augmented data\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 5e-5\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_attention_masks],\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=([valid_input_ids, valid_attention_masks], valid_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 8568,
     "status": "ok",
     "timestamp": 1680194840167,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "4I7lCokaWmk4"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/HKU/COMP7409 Machine learning in trading and finance/Project/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5864,
     "status": "ok",
     "timestamp": 1680194846017,
     "user": {
      "displayName": "Ip Wa Chan",
      "userId": "04772759590933392335"
     },
     "user_tz": -480
    },
    "id": "ude_BfSXNY-U",
    "outputId": "4c481e57-1b65-401a-eb86-4e46ec4c66f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 238ms/step\n",
      "Test Performance:\n",
      "accuracy:  58.57%\n",
      "precision: 67.61%\n",
      "recall:    57.83%\n",
      "F1 Score:  62.34%\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate the performance of the fine-tuned\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "predictions = model.predict([test_input_ids, test_attention_masks])\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "\n",
    "\n",
    "# accuracy = np.sum(predicted_labels == test_labels.numpy()) / len(test_labels)\n",
    "accuracy=accuracy_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels)\n",
    "recall = recall_score(test_labels, predicted_labels)\n",
    "f1 = f1_score(test_labels, predicted_labels)\n",
    "print(\"Test Performance:\")\n",
    "print(\"accuracy:  {:.2f}%\".format(accuracy * 100))\n",
    "print(\"precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"recall:    {:.2f}%\".format(recall * 100))\n",
    "print(\"F1 Score:  {:.2f}%\".format(f1 * 100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNNACnsjCh/Ozu5NcCyeG1j",
   "provenance": [
    {
     "file_id": "1Mh0CNNlOYJYDOjuUThKv3zraoy7RyLt4",
     "timestamp": 1679417304597
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1266ba7ee9e347ada3c42b945ea562ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eb656f8ce664c76afec024b5dc43b87",
      "placeholder": "",
      "style": "IPY_MODEL_4e80cf3471f14159a5c1c709f4c5e2e8",
      "value": "Downloading tf_model.h5: 100%"
     }
    },
    "1f56f90ecfa147f299a1fd95b602a776": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb656f8ce664c76afec024b5dc43b87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f35d66abecc4521a7b653c1990145b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e80cf3471f14159a5c1c709f4c5e2e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67445718b5dc492bbeb0a24cb3fb83e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72ea02f182c04e2b87e32cfb813ba1d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f35d66abecc4521a7b653c1990145b7",
      "placeholder": "",
      "style": "IPY_MODEL_7b6c869f8baa4c94a1157ba1f0453c9c",
      "value": " 536M/536M [00:01&lt;00:00, 284MB/s]"
     }
    },
    "7b6c869f8baa4c94a1157ba1f0453c9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6d85307452b4eaba9cda91954ca3093": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1266ba7ee9e347ada3c42b945ea562ab",
       "IPY_MODEL_f46cb9695cc7431781c675fa6a052dfa",
       "IPY_MODEL_72ea02f182c04e2b87e32cfb813ba1d5"
      ],
      "layout": "IPY_MODEL_1f56f90ecfa147f299a1fd95b602a776"
     }
    },
    "e2bb40050f20431eae41e104387fa6fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f46cb9695cc7431781c675fa6a052dfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67445718b5dc492bbeb0a24cb3fb83e3",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2bb40050f20431eae41e104387fa6fe",
      "value": 536063208
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
